{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation\n",
    "from keras.layers import Dropout, LeakyReLU       \n",
    "from keras.activations import relu, softmax, tanh, hard_sigmoid\n",
    "\n",
    "import pydot, graphviz\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob\n",
    "from PIL import Image\n",
    "import h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.losses import categorical_crossentropy\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.initializers import he_normal\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "#import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import Flatten, Input\n",
    "import scipy\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = keras.applications.densenet.DenseNet201(include_top=False, weights=None, input_shape=(224,224,3), pooling='max')\n",
    "densenet.load_weights('densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg19 = keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3), pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_pad\n",
      "2 conv1\n",
      "3 bn_conv1\n",
      "4 activation_1\n",
      "5 max_pooling2d_1\n",
      "6 res2a_branch2a\n",
      "7 bn2a_branch2a\n",
      "8 activation_2\n",
      "9 res2a_branch2b\n",
      "10 bn2a_branch2b\n",
      "11 activation_3\n",
      "12 res2a_branch2c\n",
      "13 res2a_branch1\n",
      "14 bn2a_branch2c\n",
      "15 bn2a_branch1\n",
      "16 add_1\n",
      "17 activation_4\n",
      "18 res2b_branch2a\n",
      "19 bn2b_branch2a\n",
      "20 activation_5\n",
      "21 res2b_branch2b\n",
      "22 bn2b_branch2b\n",
      "23 activation_6\n",
      "24 res2b_branch2c\n",
      "25 bn2b_branch2c\n",
      "26 add_2\n",
      "27 activation_7\n",
      "28 res2c_branch2a\n",
      "29 bn2c_branch2a\n",
      "30 activation_8\n",
      "31 res2c_branch2b\n",
      "32 bn2c_branch2b\n",
      "33 activation_9\n",
      "34 res2c_branch2c\n",
      "35 bn2c_branch2c\n",
      "36 add_3\n",
      "37 activation_10\n",
      "38 res3a_branch2a\n",
      "39 bn3a_branch2a\n",
      "40 activation_11\n",
      "41 res3a_branch2b\n",
      "42 bn3a_branch2b\n",
      "43 activation_12\n",
      "44 res3a_branch2c\n",
      "45 res3a_branch1\n",
      "46 bn3a_branch2c\n",
      "47 bn3a_branch1\n",
      "48 add_4\n",
      "49 activation_13\n",
      "50 res3b_branch2a\n",
      "51 bn3b_branch2a\n",
      "52 activation_14\n",
      "53 res3b_branch2b\n",
      "54 bn3b_branch2b\n",
      "55 activation_15\n",
      "56 res3b_branch2c\n",
      "57 bn3b_branch2c\n",
      "58 add_5\n",
      "59 activation_16\n",
      "60 res3c_branch2a\n",
      "61 bn3c_branch2a\n",
      "62 activation_17\n",
      "63 res3c_branch2b\n",
      "64 bn3c_branch2b\n",
      "65 activation_18\n",
      "66 res3c_branch2c\n",
      "67 bn3c_branch2c\n",
      "68 add_6\n",
      "69 activation_19\n",
      "70 res3d_branch2a\n",
      "71 bn3d_branch2a\n",
      "72 activation_20\n",
      "73 res3d_branch2b\n",
      "74 bn3d_branch2b\n",
      "75 activation_21\n",
      "76 res3d_branch2c\n",
      "77 bn3d_branch2c\n",
      "78 add_7\n",
      "79 activation_22\n",
      "80 res4a_branch2a\n",
      "81 bn4a_branch2a\n",
      "82 activation_23\n",
      "83 res4a_branch2b\n",
      "84 bn4a_branch2b\n",
      "85 activation_24\n",
      "86 res4a_branch2c\n",
      "87 res4a_branch1\n",
      "88 bn4a_branch2c\n",
      "89 bn4a_branch1\n",
      "90 add_8\n",
      "91 activation_25\n",
      "92 res4b_branch2a\n",
      "93 bn4b_branch2a\n",
      "94 activation_26\n",
      "95 res4b_branch2b\n",
      "96 bn4b_branch2b\n",
      "97 activation_27\n",
      "98 res4b_branch2c\n",
      "99 bn4b_branch2c\n",
      "100 add_9\n",
      "101 activation_28\n",
      "102 res4c_branch2a\n",
      "103 bn4c_branch2a\n",
      "104 activation_29\n",
      "105 res4c_branch2b\n",
      "106 bn4c_branch2b\n",
      "107 activation_30\n",
      "108 res4c_branch2c\n",
      "109 bn4c_branch2c\n",
      "110 add_10\n",
      "111 activation_31\n",
      "112 res4d_branch2a\n",
      "113 bn4d_branch2a\n",
      "114 activation_32\n",
      "115 res4d_branch2b\n",
      "116 bn4d_branch2b\n",
      "117 activation_33\n",
      "118 res4d_branch2c\n",
      "119 bn4d_branch2c\n",
      "120 add_11\n",
      "121 activation_34\n",
      "122 res4e_branch2a\n",
      "123 bn4e_branch2a\n",
      "124 activation_35\n",
      "125 res4e_branch2b\n",
      "126 bn4e_branch2b\n",
      "127 activation_36\n",
      "128 res4e_branch2c\n",
      "129 bn4e_branch2c\n",
      "130 add_12\n",
      "131 activation_37\n",
      "132 res4f_branch2a\n",
      "133 bn4f_branch2a\n",
      "134 activation_38\n",
      "135 res4f_branch2b\n",
      "136 bn4f_branch2b\n",
      "137 activation_39\n",
      "138 res4f_branch2c\n",
      "139 bn4f_branch2c\n",
      "140 add_13\n",
      "141 activation_40\n",
      "142 res5a_branch2a\n",
      "143 bn5a_branch2a\n",
      "144 activation_41\n",
      "145 res5a_branch2b\n",
      "146 bn5a_branch2b\n",
      "147 activation_42\n",
      "148 res5a_branch2c\n",
      "149 res5a_branch1\n",
      "150 bn5a_branch2c\n",
      "151 bn5a_branch1\n",
      "152 add_14\n",
      "153 activation_43\n",
      "154 res5b_branch2a\n",
      "155 bn5b_branch2a\n",
      "156 activation_44\n",
      "157 res5b_branch2b\n",
      "158 bn5b_branch2b\n",
      "159 activation_45\n",
      "160 res5b_branch2c\n",
      "161 bn5b_branch2c\n",
      "162 add_15\n",
      "163 activation_46\n",
      "164 res5c_branch2a\n",
      "165 bn5c_branch2a\n",
      "166 activation_47\n",
      "167 res5c_branch2b\n",
      "168 bn5c_branch2b\n",
      "169 activation_48\n",
      "170 res5c_branch2c\n",
      "171 bn5c_branch2c\n",
      "172 add_16\n",
      "173 activation_49\n",
      "174 avg_pool\n",
      "175 global_max_pooling2d_1\n"
     ]
    }
   ],
   "source": [
    "for i, layers in enumerate(resnet.layers):\n",
    "    print(i, layers.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hist_equ(img_path = '', show = False, img = None):\n",
    "    if img is None:\n",
    "        img = cv2.imread(data_path + img_path)\n",
    "\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV) # RGB to YUB color space\n",
    "\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0]) # histogram equalization in Y channel\n",
    "\n",
    "    equ = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR) # inverse transform\n",
    "    \n",
    "    if show:    \n",
    "        comp = np.hstack((img,equ)) # horizontal stack\n",
    "        cv2.imwrite('original.bmp',img)\n",
    "        cv2.imwrite('hist_equ.bmp',equ)\n",
    "        cv2.imwrite('comp.bmp',comp)\n",
    "        plt.imshow(comp)\n",
    "        plt.show()\n",
    "    return equ\n",
    "\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    " \n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_segmented_images(_class,_id,data_split,flag_show):\n",
    "\n",
    "    _class = str(_class)\n",
    "    _id = str(_id)\n",
    "    \n",
    "    imgpath = 'PH2 Dataset images/'+'/IMD'+_id+'/IMD'+_id+'_Dermoscopic_Image/IMD'+_id+'.bmp'  \n",
    "    maskpath = 'PH2 Dataset images/'+'/IMD'+_id+'/IMD'+_id+'_lesion/IMD'+_id+'_lesion.bmp'\n",
    "    img = cv2.imread(imgpath)\n",
    "    #img = hist_equ(img = img2) # not using any pre-processing\n",
    "    #img = adjust_gamma(img, 1.55)\n",
    "    msk = cv2.imread(maskpath)\n",
    "    \n",
    "    #cv2.imshow('Main Image',img)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    if flag_show:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        #print(img.shape)\n",
    "\n",
    "        plt.imshow(msk)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    msk = msk/255 # normalizing\n",
    "    max_channels = np.amax([np.amax(msk[:,:,0]), np.amax(msk[:,:,1]), np.amax(msk[:,:,2])])\n",
    "    \n",
    "    msk = np.ndarray.astype(msk, dtype='uint8')\n",
    "    \n",
    "    gen_img = img*msk\n",
    "    dirc = 'F:/Research important/Thesis/Active Phase/Part1 Scin Cancer/PH2Dataset experiments/classification/' + data_split\n",
    "    dirc = os.path.join(dirc,_class)\n",
    "    if not os.path.exists(dirc):\n",
    "        os.makedirs(dirc)\n",
    "        \n",
    "    gen_img_name =  dirc + '/' + _id + '.png'\n",
    "    cv2.imwrite(gen_img_name,gen_img)\n",
    "    if flag_show:\n",
    "        print(max_channels)\n",
    "        plt.imshow(gen_img)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Image Name', 'Histological Diagnosis', 'Common Nevus',\n",
      "       'Atypical Nevus', 'Melanoma', 'Asymmetry\\n(0/1/2)',\n",
      "       'Pigment Network\\n(AT/T)', 'Dots/Globules\\n(A/AT/T)', 'Streaks\\n(A/P)',\n",
      "       'Regression Areas\\n(A/P)', 'Blue-Whitish Veil\\n(A/P)', 'White', 'Red',\n",
      "       'Light-Brown', 'Dark-Brown', 'Blue-Gray', 'Black'],\n",
      "      dtype='object')\n",
      "IMD003\n",
      "X\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Common Nevus</th>\n",
       "      <th>Atypical Nevus</th>\n",
       "      <th>Melanoma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMD009</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMD016</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMD022</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image Name Common Nevus Atypical Nevus Melanoma\n",
       "1     IMD009            X            NaN      NaN\n",
       "2     IMD016            X            NaN      NaN\n",
       "3     IMD022            X            NaN      NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_excel('PH2_dataset.xlsx') # The excel file was modified, unnecessary info was removed\n",
    "#print the column names\n",
    "print (df.columns)\n",
    "#get the values for a given column\n",
    "values = df['Image Name'].values\n",
    "#get a data frame with selected columns\n",
    "FORMAT = ['Image Name', 'Common Nevus', 'Atypical Nevus', 'Melanoma']\n",
    "df_selected = df[FORMAT]\n",
    "print(df_selected.loc[0][0])\n",
    "print(df_selected.loc[0][1])\n",
    "print(type(df_selected.loc[0][0]))\n",
    "df_selected[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = 200\n",
    "class0 = []\n",
    "class1 = []\n",
    "class2 = []\n",
    "for ns in range(num_samples):\n",
    "    img_id = df_selected.loc[ns][0][-3:]\n",
    "    com_nev = df_selected.loc[ns][1]\n",
    "    atyp_nev = df_selected.loc[ns][2]\n",
    "    melan = df_selected.loc[ns][3]\n",
    "    _class = -1\n",
    "    if com_nev == 'X':\n",
    "        _class = 0\n",
    "        class0.append(img_id)\n",
    "    elif atyp_nev == 'X':\n",
    "        _class = 1\n",
    "        class1.append(img_id)\n",
    "    elif melan == 'X':\n",
    "        _class = 2\n",
    "        class2.append(img_id)\n",
    "    #print(_class)\n",
    "    #generate_segmented_images(_class,img_id,flag_show = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['134', '394', '159', '390', '161', '177', '039', '017', '372', '397', '022', '041', '101', '150', '374', '380', '147', '050', '132', '395', '371', '378', '045', '207', '112', '399', '016', '010', '175', '199', '118', '197', '092', '003', '025', '383', '375', '208', '144', '176', '364', '392', '198', '182', '400', '365', '024', '152', '042', '173', '125', '135', '143', '103', '035', '385', '206', '196', '402', '160', '162', '146', '105', '381']\n",
      "['009', '384', '204', '133', '379', '156', '107', '367', '389', '044', '203', '142', '200', '108', '038', '020']\n",
      "['431', '032', '166', '356', '018', '430', '376', '153', '339', '031', '368', '256', '382', '169', '013', '139', '278', '036', '140', '436', '254', '279', '331', '437', '434', '006', '280', '078', '043', '433', '226', '328', '306', '138', '075', '033', '210', '398', '027', '396', '360', '171', '393', '427', '008', '347', '015', '170', '040', '243', '021', '048', '304', '386', '305', '157', '312', '432', '019', '120', '369', '370', '155', '251']\n",
      "['137', '049', '149', '002', '154', '037', '164', '014', '057', '388', '004', '023', '030', '047', '076', '126']\n",
      "['080', '418', '420', '091', '284', '405', '421', '406', '429', '064', '063', '085', '404', '065', '219', '435', '419', '211', '090', '411', '403', '058', '424', '423', '240', '425', '409', '168', '410', '413', '242', '285']\n",
      "['408', '088', '349', '061', '426', '407', '417', '348']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0) # to reproduce results\n",
    "\n",
    "train_split = 0.80\n",
    "random.shuffle(class0)\n",
    "random.shuffle(class1)\n",
    "random.shuffle(class2)\n",
    "\n",
    "train_0 = class0[0:int(len(class0)*train_split)]\n",
    "test_0 = class0[int(len(class0)*train_split):]\n",
    "print(train_0)\n",
    "print(test_0)\n",
    "\n",
    "train_1 = class1[0:int(len(class1)*train_split)]\n",
    "test_1 = class1[int(len(class1)*train_split):]\n",
    "print(train_1)\n",
    "print(test_1)\n",
    "\n",
    "train_2 = class2[0:int(len(class2)*train_split)]\n",
    "test_2 = class2[int(len(class2)*train_split):]\n",
    "print(train_2)\n",
    "print(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_0)):\n",
    "    generate_segmented_images(0,train_0[i],'train',flag_show = False)\n",
    "\n",
    "for i in range(len(test_0)):\n",
    "    generate_segmented_images(0,test_0[i],'test',flag_show = False)\n",
    "    \n",
    "for i in range(len(train_1)):\n",
    "    generate_segmented_images(1,train_1[i],'train',flag_show = False)\n",
    "\n",
    "for i in range(len(test_1)):\n",
    "    generate_segmented_images(1,test_1[i],'test',flag_show = False)\n",
    "    \n",
    "    \n",
    "for i in range(len(train_2)):\n",
    "    generate_segmented_images(2,train_2[i],'train',flag_show = False)\n",
    "\n",
    "for i in range(len(test_2)):\n",
    "    generate_segmented_images(2,test_2[i],'test',flag_show = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train_aug'\n",
    "test_path = 'test'\n",
    "\n",
    "random_seed = 1997\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Extract features from an arbitrary intermediate layer\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "#model_fe = Model(inputs=cmod.input, outputs=cmod.get_layer('conv2d_6').output)\n",
    "\n",
    "\n",
    "# use ResNet50 model extract feature from fc1 layer\n",
    "base_model1 = None #vgg19 #ResNet50(weights='imagenet', pooling=max, include_top = False)\n",
    "base_model2 = resnet #resnet #ResNet50(weights='imagenet', pooling=max, include_top = False)\n",
    "\n",
    "input = Input(shape=(224,224,3),name = 'image_input')\n",
    "#x = base_model1(input)\n",
    "#x1 = Flatten()(x)\n",
    "#model1 = Model(inputs=input, outputs=x1)\n",
    "\n",
    "x_ = base_model2(input)\n",
    "#x2 = Flatten()(x_)\n",
    "model2 = Model(inputs=input, outputs=x_)\n",
    "\n",
    "X_train_vgg19 = []\n",
    "X_train_resnet = []\n",
    "X_train_mod3 = []\n",
    "y_train = []\n",
    "\n",
    "for class_ in range(3):\n",
    "    for fnam in glob.glob(os.path.join(train_path,str(class_),'*')):\n",
    "        img = image.load_img(fnam, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        #features1 = model1.predict(x)\n",
    "        #features_reduce1 =  features1.squeeze()\n",
    "        #X_train_vgg19.append(features_reduce1)\n",
    "        \n",
    "        features2 = model2.predict(x)\n",
    "        features_reduce2 =  features2.squeeze()\n",
    "        X_train_resnet.append(features_reduce2)\n",
    "        \n",
    "        #features3 = model_fe.predict(x)\n",
    "        #features_reduce3 =  features3.squeeze()\n",
    "        #X_train_mod3.append(features_reduce3)\n",
    "\n",
    "        targets = np.zeros(3)\n",
    "        targets[class_] = 1\n",
    "        y_train.append(targets)\n",
    "\n",
    "#X = np.array(X_train_vgg19 + X_train_resnet)\n",
    "y = np.array(y_train, np.uint8)\n",
    "\n",
    "X_test_vgg19 = []\n",
    "X_test_resnet = []\n",
    "X_test_mod3 = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for class_ in range(3):\n",
    "    for fnam in glob.glob(os.path.join(test_path,str(class_),'*')):\n",
    "        img = image.load_img(fnam, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        #features1 = model1.predict(x)\n",
    "        #features_reduce1 =  features1.squeeze()\n",
    "        #X_test_vgg19.append(features_reduce1)\n",
    "        \n",
    "        features2 = model2.predict(x)\n",
    "        features_reduce2 =  features2.squeeze()\n",
    "        X_test_resnet.append(features_reduce2)\n",
    "        \n",
    "        #features3 = model_fe.predict(x)\n",
    "        #features_reduce3 =  features3.squeeze()\n",
    "        #X_test_mod3.append(features_reduce3)\n",
    "        \n",
    "        \n",
    "        y_test.append(class_)\n",
    "\n",
    "#X_test = X_test_vgg19 + X_test_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,)\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(X_test_resnet[0].shape)\n",
    "print(type(X_test_resnet))\n",
    "print(type(X_train_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(X_train_resnet)):\n",
    "    cx = [] \n",
    "    for j in range(len(X_train_resnet[0])):\n",
    "        cx.append(X_train_resnet[i][j])#np.array(X_train_vgg19 + X_train_resnet)\n",
    "    #for j in range(len(X_train_resnet[0])):\n",
    "    #    cx.append(X_train_resnet[i][j])#np.array(X_train_vgg19 + X_train_resnet)\n",
    "    #for j in range(len(X_train_mod3[0])):\n",
    "    #    cx.append(X_train_mod3[i][j])#np.array(X_train_vgg19 + X_train_resnet)\n",
    "        \n",
    "    X.append(cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(len(X_test_resnet)):\n",
    "    cx = [] \n",
    "    for j in range(len(X_test_resnet[0])):\n",
    "        cx.append(X_test_resnet[i][j])#np.array(X_train_vgg19 + X_train_resnet)\n",
    "    #for j in range(len(X_test_resnet[0])):\n",
    "    #    cx.append(X_test_resnet[i][j])#np.array(X_train_vgg19 + X_train_resnet)\n",
    "    #for j in range(len(X_test_mod3[0])):\n",
    "    #    cx.append(X_test_mod3[i][j])\n",
    "        \n",
    "    X_test.append(cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  ...\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]]\n",
      "\n",
      " [[-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  ...\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]]\n",
      "\n",
      " [[-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  ...\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  ...\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]]\n",
      "\n",
      " [[-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  ...\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]]\n",
      "\n",
      " [[-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  ...\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]\n",
      "  [-427.66324 -113.42633 -314.65555 ... -287.33    -256.3068  -134.88426]]]\n"
     ]
    }
   ],
   "source": [
    "X_train_mod3 = np.array(X_train_mod3)\n",
    "print(X_train_mod3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 215, 215, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mod3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_mod3 = np.array(X_test_mod3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 215, 215, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mod3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_mod3_conv = np.reshape(X_train_mod3,(460,1479200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_mod3_conv = np.reshape(X_test_mod3,(40,1479200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "            class_weight=[{0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 2}],\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(n_jobs=2, random_state=0,class_weight = [{0:1,1:1},\n",
    "                                                                     {0:1,1:1},\n",
    "                                                                     {0:1,1:2}])\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(X_train_resnet, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = [] # 16, 16, 8\n",
    "for i in range(16):\n",
    "    y_test.append(0)\n",
    "for i in range(16):\n",
    "    y_test.append(1)\n",
    "for i in range(8):\n",
    "    y_test.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_v = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(pred_v,axis=1)\n",
    "print(pred[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "tot = 0\n",
    "for i in range(len(pred)):\n",
    "    if(pred[i]==y_test[i]):\n",
    "        cnt+=1\n",
    "    #if(pred[i]==0 and y_test[i]==1):\n",
    "    #    cnt+=1\n",
    "    #if(pred[i]==1 and y_test[i]==0):\n",
    "    #    cnt+=1\n",
    "    \n",
    "    tot += 1\n",
    "print(cnt/tot)   # resnet 2 class - 87.5, 3 class - 62.5\n",
    "                 # vgg19  2 class - 0.5,  3 class - 85\n",
    "                 # feature concat 3 class -  57.5  ,  2 class - 90\n",
    "                 # augmentation + feature concat 3 class 0.675, 2 class 90%\n",
    "                 # augmentation + mod3 2 class 90%, 2 class .55, features extracted from last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "0   0\n",
      "1   0\n",
      "1   0\n",
      "0   0\n",
      "0   0\n",
      "1   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "1   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "0   1\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "2   2\n",
      "0   2\n",
      "2   2\n",
      "2   2\n",
      "0   2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred)):\n",
    "    print(pred[i],' ',y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 160 image(s) found.\n",
      "Output directory set to train\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=766x576 at 0xFFB70E7B00>: 100%|â–ˆ| 100/100 [00:08<00:00, 12.17 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "## augmentation\n",
    "import Augmentor\n",
    "p = Augmentor.Pipeline(\"train\")\n",
    "#p.random_distortion(probability = 1, grid_width = 10, grid_height = 10, magnitude = 10)\n",
    "#p.flip_random(probability = 1)\n",
    "p.rotate_without_crop(probability=1, max_left_rotation=360, max_right_rotation=360, expand=False)\n",
    "p.skew(probability=1, magnitude=0.8)\n",
    "p.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmod = load_model('best_weight3_mod.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 220, 220, 16)      1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 219, 219, 16)      0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 219, 219, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 215, 215, 32)      12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 107, 107, 32)      0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 107, 107, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 366368)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 156)               57153564  \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 156)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 156)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 471       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 57,168,083\n",
      "Trainable params: 57,168,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cmod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features from an arbitrary intermediate layer\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "model_fe = Model(inputs=cmod.input, outputs=cmod.get_layer('conv2d_6').output)\n",
    "\n",
    "# load an image and preprocess it\n",
    "img_path = 'test.bmp'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# get the features \n",
    "features = model_fe.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
